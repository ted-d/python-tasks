{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9507bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas>=1.3.0 in /home/tm/Рабочий стол/ projects/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (2.3.0)\n",
      "Requirement already satisfied: openpyxl>=3.0.0 in /home/tm/Рабочий стол/ projects/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (3.1.5)\n",
      "Collecting sqlalchemy>=1.4.0 (from -r requirements.txt (line 3))\n",
      "  Downloading sqlalchemy-2.0.41-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting psycopg2-binary>=2.9.0 (from -r requirements.txt (line 4))\n",
      "  Downloading psycopg2_binary-2.9.10-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting python-dotenv>=0.19.0 (from -r requirements.txt (line 5))\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting jupyter>=1.0.0 (from -r requirements.txt (line 6))\n",
      "  Downloading jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: ipykernel>=6.0.0 in /home/tm/Рабочий стол/ projects/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (6.29.5)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/tm/Рабочий стол/ projects/.venv/lib/python3.12/site-packages (from pandas>=1.3.0->-r requirements.txt (line 1)) (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/tm/Рабочий стол/ projects/.venv/lib/python3.12/site-packages (from pandas>=1.3.0->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/tm/Рабочий стол/ projects/.venv/lib/python3.12/site-packages (from pandas>=1.3.0->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/tm/Рабочий стол/ projects/.venv/lib/python3.12/site-packages (from pandas>=1.3.0->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: et-xmlfile in /home/tm/Рабочий стол/ projects/.venv/lib/python3.12/site-packages (from openpyxl>=3.0.0->-r requirements.txt (line 2)) (2.0.0)\n",
      "Collecting greenlet>=1 (from sqlalchemy>=1.4.0->-r requirements.txt (line 3))\n",
      "  Downloading greenlet-3.2.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting typing-extensions>=4.6.0 (from sqlalchemy>=1.4.0->-r requirements.txt (line 3))\n",
      "  Downloading typing_extensions-4.14.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting notebook (from jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading notebook-7.4.3-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jupyter-console (from jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading jupyter_console-6.6.3-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting nbconvert (from jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading nbconvert-7.16.6-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting ipywidgets (from jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading ipywidgets-8.1.7-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting jupyterlab (from jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading jupyterlab-4.4.3-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: comm>=0.1.1 in /home/tm/Рабочий стол/ projects/.venv/lib/python3.12/site-packages (from ipykernel>=6.0.0->-r requirements.txt (line 7)) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /home/tm/Рабочий стол/ projects/.venv/lib/python3.12/site-packages (from ipykernel>=6.0.0->-r requirements.txt (line 7)) (1.8.14)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /home/tm/Рабочий стол/ projects/.venv/lib/python3.12/site-packages (from ipykernel>=6.0.0->-r requirements.txt (line 7)) (9.3.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /home/tm/Рабочий стол/ projects/.venv/lib/python3.12/site-packages (from ipykernel>=6.0.0->-r requirements.txt (line 7)) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /home/tm/Рабочий стол/ projects/.venv/lib/python3.12/site-packages (from ipykernel>=6.0.0->-r requirements.txt (line 7)) (5.8.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /home/tm/Рабочий стол/ projects/.venv/lib/python3.12/site-packages (from ipykernel>=6.0.0->-r requirements.txt (line 7)) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in /home/tm/Рабочий стол/ projects/.venv/lib/python3.12/site-packages (from ipykernel>=6.0.0->-r requirements.txt (line 7)) (1.6.0)\n",
      "Requirement already satisfied: packaging in /home/tm/Рабочий стол/ projects/.venv/lib/python3.12/site-packages (from ipykernel>=6.0.0->-r requirements.txt (line 7)) (25.0)\n",
      "Requirement already satisfied: psutil in /home/tm/Рабочий стол/ projects/.venv/lib/python3.12/site-packages (from ipykernel>=6.0.0->-r requirements.txt (line 7)) (7.0.0)\n",
      "Requirement already satisfied: pyzmq>=24 in /home/tm/Рабочий стол/ projects/.venv/lib/python3.12/site-packages (from ipykernel>=6.0.0->-r requirements.txt (line 7)) (27.0.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /home/tm/Рабочий стол/ projects/.venv/lib/python3.12/site-packages (from ipykernel>=6.0.0->-r requirements.txt (line 7)) (6.5.1)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /home/tm/Рабочий стол/ projects/.venv/lib/python3.12/site-packages (from ipykernel>=6.0.0->-r requirements.txt (line 7)) (5.14.3)\n",
      "Requirement already satisfied: decorator in /home/tm/Рабочий стол/ projects/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.0.0->-r requirements.txt (line 7)) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /home/tm/Рабочий стол/ projects/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.0.0->-r requirements.txt (line 7)) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/tm/Рабочий стол/ projects/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.0.0->-r requirements.txt (line 7)) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/tm/Рабочий стол/ projects/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.0.0->-r requirements.txt (line 7)) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /home/tm/Рабочий стол/ projects/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.0.0->-r requirements.txt (line 7)) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/tm/Рабочий стол/ projects/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.0.0->-r requirements.txt (line 7)) (2.19.2)\n",
      "Requirement already satisfied: stack_data in /home/tm/Рабочий стол/ projects/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.0.0->-r requirements.txt (line 7)) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in /home/tm/Рабочий стол/ projects/.venv/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel>=6.0.0->-r requirements.txt (line 7)) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/tm/Рабочий стол/ projects/.venv/lib/python3.12/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=6.0.0->-r requirements.txt (line 7)) (0.8.4)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/tm/Рабочий стол/ projects/.venv/lib/python3.12/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=6.0.0->-r requirements.txt (line 7)) (4.3.8)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/tm/Рабочий стол/ projects/.venv/lib/python3.12/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel>=6.0.0->-r requirements.txt (line 7)) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/tm/Рабочий стол/ projects/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->-r requirements.txt (line 1)) (1.17.0)\n",
      "Collecting widgetsnbextension~=4.0.14 (from ipywidgets->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting async-lru>=1.0.0 (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting httpx>=0.25.0 (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jinja2>=3.0.3 (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting jupyter-lsp>=2.0.0 (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading jupyter_lsp-2.2.5-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting jupyter-server<3,>=2.4.0 (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading jupyter_server-2.16.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting jupyterlab-server<3,>=2.27.1 (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting notebook-shim>=0.2 (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading notebook_shim-0.2.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting setuptools>=41.1.0 (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting anyio>=3.1.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting argon2-cffi>=21.1 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading argon2_cffi-25.1.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting jupyter-events>=0.11.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting nbformat>=5.3.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting prometheus-client>=0.9 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading prometheus_client-0.22.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting send2trash>=1.8.2 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading Send2Trash-1.8.3-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting terminado>=0.8.3 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading terminado-0.18.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting websocket-client>=1.7 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting babel>=2.10 (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading babel-2.17.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading json5-0.12.0-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting jsonschema>=4.18.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading jsonschema-4.24.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting requests>=2.31 (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting idna>=2.8 (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting sniffio>=1.1 (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting argon2-cffi-bindings (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting certifi (from httpx>=0.25.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading certifi-2025.6.15-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting httpcore==1.* (from httpx>=0.25.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.25.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2>=3.0.3->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=22.2.0 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading rpds_py-0.25.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading python_json_logger-3.3.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting pyyaml>=5.3 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting rfc3339-validator (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jsonpointer>1.13 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting webcolors>=24.6.0 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading webcolors-24.11.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting beautifulsoup4 (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading beautifulsoup4-4.13.4-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting bleach!=5.0.0 (from bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading bleach-6.2.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting defusedxml (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting jupyterlab-pygments (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading jupyterlab_pygments-0.3.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting mistune<4,>=2.0.3 (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading mistune-3.1.3-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting nbclient>=0.5.0 (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading nbclient-0.10.2-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting pandocfilters>=1.4.1 (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading pandocfilters-1.5.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting webencodings (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting tinycss2<1.5,>=1.1.0 (from bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading tinycss2-1.4.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting fastjsonschema>=2.15 (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading fastjsonschema-2.21.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading charset_normalizer-3.4.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting cffi>=1.0.1 (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading cffi-1.17.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting pycparser (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading soupsieve-2.7-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading types_python_dateutil-2.9.0.20250516-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/tm/Рабочий стол/ projects/.venv/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel>=6.0.0->-r requirements.txt (line 7)) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/tm/Рабочий стол/ projects/.venv/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel>=6.0.0->-r requirements.txt (line 7)) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /home/tm/Рабочий стол/ projects/.venv/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel>=6.0.0->-r requirements.txt (line 7)) (0.2.3)\n",
      "Downloading sqlalchemy-2.0.41-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading psycopg2_binary-2.9.10-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
      "Downloading greenlet-3.2.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (605 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m605.5/605.5 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.14.0-py3-none-any.whl (43 kB)\n",
      "Downloading ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
      "Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl (216 kB)\n",
      "Downloading widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
      "Downloading jupyterlab-4.4.3-py3-none-any.whl (12.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jupyter_server-2.16.0-py3-none-any.whl (386 kB)\n",
      "Downloading jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
      "Downloading anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Downloading argon2_cffi-25.1.0-py3-none-any.whl (14 kB)\n",
      "Downloading async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
      "Downloading babel-2.17.0-py3-none-any.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading json5-0.12.0-py3-none-any.whl (36 kB)\n",
      "Downloading jsonschema-4.24.0-py3-none-any.whl (88 kB)\n",
      "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
      "Downloading jupyter_events-0.12.0-py3-none-any.whl (19 kB)\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)\n",
      "Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
      "Downloading nbconvert-7.16.6-py3-none-any.whl (258 kB)\n",
      "Downloading mistune-3.1.3-py3-none-any.whl (53 kB)\n",
      "Downloading bleach-6.2.0-py3-none-any.whl (163 kB)\n",
      "Downloading tinycss2-1.4.0-py3-none-any.whl (26 kB)\n",
      "Downloading nbclient-0.10.2-py3-none-any.whl (25 kB)\n",
      "Downloading nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "Downloading fastjsonschema-2.21.1-py3-none-any.whl (23 kB)\n",
      "Downloading notebook_shim-0.2.4-py3-none-any.whl (13 kB)\n",
      "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading pandocfilters-1.5.1-py2.py3-none-any.whl (8.7 kB)\n",
      "Downloading prometheus_client-0.22.1-py3-none-any.whl (58 kB)\n",
      "Downloading python_json_logger-3.3.0-py3-none-any.whl (15 kB)\n",
      "Downloading PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (767 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m767.5/767.5 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (148 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading certifi-2025.6.15-py3-none-any.whl (157 kB)\n",
      "Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Downloading rpds_py-0.25.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (390 kB)\n",
      "Downloading Send2Trash-1.8.3-py3-none-any.whl (18 kB)\n",
      "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading terminado-0.18.1-py3-none-any.whl (14 kB)\n",
      "Downloading webcolors-24.11.1-py3-none-any.whl (14 kB)\n",
      "Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Downloading argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (86 kB)\n",
      "Downloading cffi-1.17.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (479 kB)\n",
      "Downloading beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
      "Downloading soupsieve-2.7-py3-none-any.whl (36 kB)\n",
      "Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
      "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
      "Downloading types_python_dateutil-2.9.0.20250516-py3-none-any.whl (14 kB)\n",
      "Downloading jupyterlab_pygments-0.3.0-py3-none-any.whl (15 kB)\n",
      "Downloading notebook-7.4.3-py3-none-any.whl (14.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.3/14.3 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
      "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: webencodings, fastjsonschema, widgetsnbextension, websocket-client, webcolors, urllib3, uri-template, typing-extensions, types-python-dateutil, tinycss2, terminado, soupsieve, sniffio, setuptools, send2trash, rpds-py, rfc3986-validator, rfc3339-validator, pyyaml, python-json-logger, python-dotenv, pycparser, psycopg2-binary, prometheus-client, pandocfilters, overrides, mistune, MarkupSafe, jupyterlab_widgets, jupyterlab-pygments, jsonpointer, json5, idna, h11, greenlet, fqdn, defusedxml, charset_normalizer, certifi, bleach, babel, attrs, async-lru, sqlalchemy, requests, referencing, jupyter-server-terminals, jinja2, httpcore, cffi, beautifulsoup4, arrow, anyio, jsonschema-specifications, isoduration, ipywidgets, httpx, argon2-cffi-bindings, jupyter-console, jsonschema, argon2-cffi, nbformat, nbclient, jupyter-events, nbconvert, jupyter-server, notebook-shim, jupyterlab-server, jupyter-lsp, jupyterlab, notebook, jupyter\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72/72\u001b[0m [jupyter]0/72\u001b[0m [notebook]b]server]minals]\n",
      "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.2 anyio-4.9.0 argon2-cffi-25.1.0 argon2-cffi-bindings-21.2.0 arrow-1.3.0 async-lru-2.0.5 attrs-25.3.0 babel-2.17.0 beautifulsoup4-4.13.4 bleach-6.2.0 certifi-2025.6.15 cffi-1.17.1 charset_normalizer-3.4.2 defusedxml-0.7.1 fastjsonschema-2.21.1 fqdn-1.5.1 greenlet-3.2.3 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.10 ipywidgets-8.1.7 isoduration-20.11.0 jinja2-3.1.6 json5-0.12.0 jsonpointer-3.0.0 jsonschema-4.24.0 jsonschema-specifications-2025.4.1 jupyter-1.1.1 jupyter-console-6.6.3 jupyter-events-0.12.0 jupyter-lsp-2.2.5 jupyter-server-2.16.0 jupyter-server-terminals-0.5.3 jupyterlab-4.4.3 jupyterlab-pygments-0.3.0 jupyterlab-server-2.27.3 jupyterlab_widgets-3.0.15 mistune-3.1.3 nbclient-0.10.2 nbconvert-7.16.6 nbformat-5.10.4 notebook-7.4.3 notebook-shim-0.2.4 overrides-7.7.0 pandocfilters-1.5.1 prometheus-client-0.22.1 psycopg2-binary-2.9.10 pycparser-2.22 python-dotenv-1.1.1 python-json-logger-3.3.0 pyyaml-6.0.2 referencing-0.36.2 requests-2.32.4 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 rpds-py-0.25.1 send2trash-1.8.3 setuptools-80.9.0 sniffio-1.3.1 soupsieve-2.7 sqlalchemy-2.0.41 terminado-0.18.1 tinycss2-1.4.0 types-python-dateutil-2.9.0.20250516 typing-extensions-4.14.0 uri-template-1.3.0 urllib3-2.5.0 webcolors-24.11.1 webencodings-0.5.1 websocket-client-1.8.0 widgetsnbextension-4.0.14\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b112cb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_in =r\"/home/tm/Рабочий стол/ projects/etl_project/data/in.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f033805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.utils import column_index_from_string\n",
    "\n",
    "# Ваш существующий INDICATOR_MAPPING остается без изменений\n",
    "INDICATOR_MAPPING = {\n",
    "    # Добыча УВ сырья\n",
    "    \"1.1.\": \"ДОБЫЧА УВ СЫРЬЯ. Нефть, млн. т\",\n",
    "    \"1.2.\": \"ДОБЫЧА УВ СЫРЬЯ. Конденсат, млн. т\",\n",
    "    \"1.3.\": \"ДОБЫЧА УВ СЫРЬЯ. Газ (свободный + газовая шапка), млрд. м3\",\n",
    "    \"1.4.\": \"ДОБЫЧА УВ СЫРЬЯ. Попутный газ, млрд. м3\",\n",
    "    \n",
    "    # Затраты на ГРР\n",
    "    \"2.\": \"ЗАТРАТЫ НА ГРР. ВСЕГО*, млн. р.\",\n",
    "    \"2.1.\": \"Глубокое бурение. всего, млн. р.\",\n",
    "    \"2.1.1.\": \"Параметрическое, млн. р.\",\n",
    "    \"2.1.2.\": \"Поисковое, млн. р.\",\n",
    "    \"2.1.3.\": \"Разведочное, млн. р.\",\n",
    "    \"2.2.\": \"Сейсморазведка. всего, млн. р.\",\n",
    "    \"2.2.1.\": \"Сейсморазведка 2Д, млн. р.\",\n",
    "    \"2.2.2.\": \"Сейсморазведка 3Д, млн. р.\",\n",
    "    \"2.3.\": \"НИОКР, млн. р.\",\n",
    "    \"2.4.\": \"Прочие работы, млн. р.\",\n",
    "    \n",
    "    # Результаты ГРР\n",
    "    \"3.1.\": \"Глубокое бурение. всего, м\",\n",
    "    \"3.1.1.\": \"Параметрическое, м\",\n",
    "    \"3.1.2.\": \"Поисковое, м\",\n",
    "    \"3.1.3.\": \"Разведочное, м\",\n",
    "    \"3.1.4.\": \"Закончено строительством поисковых скважин, шт.\",\n",
    "    \"3.1.4.1.\": \"Из них продуктивных, шт.\",\n",
    "    \"3.1.5.\": \"Закончено строительством разведочных скважин, шт.\",\n",
    "    \"3.1.5.1.\": \"Из них продуктивных, шт.\",\n",
    "    \n",
    "    # Прирост запасов АВ1C1\n",
    "    \"3.2.1.\": \"Прирост запасов УВ категории АВ1C1. Нефть, млн. т\",\n",
    "    \"3.2.1.1.\": \"Прирост запасов УВ категории АВ1C1. Нефть за счет ГРР, млн. т\",\n",
    "    \"3.2.1.2.\": \"Прирост запасов УВ категории АВ1C1. Нефть за счет переоценки, млн. т\",\n",
    "    \"3.2.2.\": \"Прирост запасов УВ категории АВ1C1. Конденсат, млн. т\",\n",
    "    \"3.2.2.1.\": \"Прирост запасов УВ категории АВ1C1. Конденсат за счет ГРР, млн. т\",\n",
    "    \"3.2.2.2.\": \"Прирост запасов УВ категории АВ1C1. Конденсат за счет переоценки, млн. т\",\n",
    "    \"3.2.3.\": \"Прирост запасов УВ категории АВ1C1. Газ (свободный + газовая шапка), млрд. м3\",\n",
    "    \"3.2.3.1.\": \"Прирост запасов УВ категории АВ1C1. Газ за счет ГРР, млрд. м3\",\n",
    "    \"3.2.3.2.\": \"Прирост запасов УВ категории АВ1C1. Газ за счет переоценки, млрд. м3\",\n",
    "    \"3.2.4.1.\": \"Прирост запасов УВ категории АВ1C1. Нефть на вновь открытых месторождениях, млн. т\",\n",
    "    \"3.2.4.2.\": \"Прирост запасов УВ категории АВ1C1. Конденсат на вновь открытых месторождениях, млн. т\",\n",
    "    \"3.2.4.3.\": \"Прирост запасов УВ категории АВ1C1. Газ на вновь открытых месторождениях, млрд. м3\",\n",
    "    \n",
    "    # Прирост запасов В2С2com\n",
    "    \"3.3.1.\": \"Прирост запасов УВ категории В2С2. Нефть, млн. т\",\n",
    "    \"3.3.1.1.\": \"Прирост запасов УВ категории В2С2. Нефть за счет ГРР, млн. т\",\n",
    "    \"3.3.1.2.\": \"Прирост запасов УВ категории В2С2. Нефть за счет переоценки, млн. т\",\n",
    "    \"3.3.2.\": \"Прирост запасов УВ категории В2С2. Конденсат, млн. т\",\n",
    "    \"3.3.2.1.\": \"Прирост запасов УВ категории В2С2. Конденсат за счет ГРР, млн. т\",\n",
    "    \"3.3.2.2.\": \"Прирост запасов УВ категории В2С2. Конденсат за счет переоценки, млн. т\",\n",
    "    \"3.3.3.\": \"Прирост запасов УВ категории В2С2. Газ (свободный + газовая шапка), млрд. м3\",\n",
    "    \"3.3.3.1.\": \"Прирост запасов УВ категории В2С2. Газ за счет ГРР, млрд. м3\",\n",
    "    \"3.3.3.2.\": \"Прирост запасов УВ категории В2С2. Газ за счет переоценки, млрд. м3\",\n",
    "    \"3.3.4.1.\": \"Прирост запасов УВ категории В2С2. Нефть на вновь открытых месторождениях, млн. т\",\n",
    "    \"3.3.4.2.\": \"Прирост запасов УВ катеcomгории В2С2. Конденсат на вновь открытых месторождениях, млн. т\",\n",
    "    \"3.3.4.3.\": \"Прирост запасов УВ категории В2С2. Газ на вновь открытых месторождениях, млрд. м3\",\n",
    "    \n",
    "    # Нетрадиционные источники УВС\n",
    "    \"3.4.1.\": \"Нетрадиционные источники УВС. Прирост категории АВ1С1. Сланцевый газ, млрд. м3\",\n",
    "    \"3.4.2.\": \"Нетрадиционные источники УВС. Прирост категории АВ1С1. Сланцевая нефть, млн. т\",\n",
    "    \"3.5.1.\": \"Нетрадиционные источники УВС. Прирост категории С2 (В2). Сланцевый газ, млрд. м3\",\n",
    "    \"3.5.2.\": \"Нетрадиционные источники УВС. Прирост категории С2 (В2). Сланцевая нефть, млн. т\",\n",
    "    \n",
    "    # Сейсморазведка\n",
    "    \"3.6.1.\": \"Сейсморазведка 2Д, пог. км\",\n",
    "    \"3.6.2.\": \"Сейсморазведка 3Д, км2\",\n",
    "    \n",
    "    # Подготовлено сейсморазведкой перспективных объектов\n",
    "    \"3.7.1.\": \"Подготовлено сейсморазведкой перспективных объектов с ресурсами. Нефть, шт.\",\n",
    "    \"3.7.1.1\": \"Подготовлено сейсморазведкой перспективных объектов с ресурсами. Нефть, млн. т\",\n",
    "    \"3.7.2.\": \"Подготовлено сейсморазведкой перспективных объектов с ресурсами. Газ (конденсат), шт.\",\n",
    "    \"3.7.2.1\": \"Подготовлено сейсморазведкой перспективных объектов с ресурсами. Газ, млрд. м3\",\n",
    "    \"3.7.2.2\": \"Подготовлено сейсморазведкой перспективных объектов с ресурсами. Конденсат, млн. т\",\n",
    "    \n",
    "    # Выведено (списано) по результатам бурения\n",
    "    \"3.8.1.\": \"Выведено (списано) по результатам бурения поисковых объектов. Нефть, шт.\",\n",
    "    \"3.8.1.1\": \"Выведено (списано) по результатам бурения поисковых объектов. Нефть, млн. т\",\n",
    "    \"3.8.2.\": \"Выведено (списано) по результатам бурения поисковых объектов. Газ (конденсат), шт.\",\n",
    "    \"3.8.2.1\": \"Выведено (списано) по результатам бурения поисковых объектов. Газ, млрд. м3\",\n",
    "    \"3.8.2.2\": \"Выведено (списано) по результатам бурения поисковых объектов. Конденсат, млн. т\",\n",
    "    \n",
    "    # Состояние ресурсов\n",
    "    \"3.9.1.\": \"Состояние ресурсов кат. Д0 на 01.01.2023 г. Нефть, млн. т\",\n",
    "    \"3.9.2.\": \"Состояние ресурсов кат. Д0 на 01.01.2023 г. Газ, млрд. м3\",\n",
    "    \"3.9.3.\": \"Состояние ресурсов кат. Д0 на 01.01.2023 г. Конденсат, млн. т\",\n",
    "    \n",
    "    # Открыто месторождений\n",
    "    \"3.10.\": \"Открыто месторождений, всего, шт.\",\n",
    "    \"3.10.1.\": \"Открыто месторождений, нефтяных, шт.\",\n",
    "    \"3.10.2.\": \"Открыто месторождений, газовых, шт.\",\n",
    "    \"3.10.3.\": \"Открыто месторождений, нефтегазовых и газонефтяных, шт.\",\n",
    "    \"3.10.4.\": \"Открыто месторождений, нефтегазоконденсатных и газоконденсатных, шт.\",\n",
    "    \n",
    "    # Оценка выполнения лицензионных условий\n",
    "    \"4.\": \"Оценка выполнения лицензионных условий, балл\"\n",
    "}\n",
    "REGION_NORMALIZATION = {\n",
    "    r'хмао[\\s\\-]?югр[аы]': 'ХМАО — Югра',\n",
    "    r'ханты[\\s\\-]мансийск[\\w\\s\\-]*югр[аы]': 'ХМАО — Югра',\n",
    "    r'ямал[\\w\\s\\-]*округ': 'Ямало-Ненецкий АО',\n",
    "    r'ямальск[\\w\\s\\-]*район': 'Ямало-Ненецкий АО',\n",
    "    r'янао': 'Ямало-Ненецкий АО'\n",
    "}\n",
    "def normalize_region(region_name):\n",
    "    \"\"\"Приводит название региона к стандартному виду\"\"\"\n",
    "    if not region_name or not isinstance(region_name, str):\n",
    "        return None\n",
    "    \n",
    "    # Приводим к нижнему регистру и удаляем лишние символы\n",
    "    cleaned = re.sub(r'[^\\w\\s\\-]', '', region_name.lower().strip())\n",
    "    \n",
    "    # Ищем совпадения с нашим словарем\n",
    "    for pattern, standard in REGION_NORMALIZATION.items():\n",
    "        if re.search(pattern, cleaned):\n",
    "            return standard\n",
    "    \n",
    "    # Если не нашли совпадение, возвращаем оригинал с базовой очисткой\n",
    "    return region_name.strip()\n",
    "def extract_company(text):\n",
    "    # Нормализация текста\n",
    "    text = re.sub(r'_{2,}', ' ', text)  # Заменяем множественные подчеркивания\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Заменяем множественные пробелы\n",
    "    text = text.replace('«', '\"').replace('»', '\"')  # Стандартизируем кавычки\n",
    "    \n",
    "    # Улучшенный паттерн поиска\n",
    "    pattern = r'''\n",
    "        (ПАО|АО|ООО|ЗАО|НКО)  # Тип организации\n",
    "        \\s*                    # Возможные пробелы\n",
    "        \"                      # Открывающая кавычка\n",
    "        (                      # Начинаем захват названия\n",
    "          (?:                  # Группа без захвата\n",
    "            [^\"\\n]+            # Любые символы кроме кавычки и переноса строки\n",
    "            (?:\"[^\"\\n]+)*      # Вложенные кавычки с текстом\n",
    "          )                    #\n",
    "        )                      # Конец названия\n",
    "        \"                      # Закрывающая кавычка\n",
    "        (?!\\S)                 # Не должно быть букв/цифр после\n",
    "    '''\n",
    "    \n",
    "    match = re.search(pattern, text, re.VERBOSE | re.IGNORECASE)\n",
    "    if match:\n",
    "        company_type = match.group(1).upper()\n",
    "        company_name = match.group(2)\n",
    "        \n",
    "        # Очистка названия (без обрезания существенной части)\n",
    "        clean_name = company_name.strip(' _-')\n",
    "        return f'{company_type} \"{clean_name}\"'\n",
    "    \n",
    "    # Дополнительный поиск для случаев с большим количеством пробелов\n",
    "    alt_pattern = r'(ПАО|АО|ООО|ЗАО|НКО)\\s+\"([^\"]+)\"'\n",
    "    alt_match = re.search(alt_pattern, text, re.IGNORECASE)\n",
    "    if alt_match:\n",
    "        return f'{alt_match.group(1).upper()} \"{alt_match.group(2).strip()}\"'\n",
    "    \n",
    "    return None\n",
    "def cut_company_name(company):\n",
    "    company = company.split()\n",
    "    if len(company)>=3:\n",
    "        company=company[:3]\n",
    "    return \" \".join(company)\n",
    "\n",
    "def extract_metadata(sheet):\n",
    "    \"\"\"Извлекает метаданные из листа\"\"\"\n",
    "    metadata = {\n",
    "        'subject':None,\n",
    "        'company': None,\n",
    "        'license': None,\n",
    "        'area': None,\n",
    "        'vink': None\n",
    "    }\n",
    "    \n",
    "    # Поиск названия компании\n",
    "    for row in sheet.iter_rows(values_only=True):\n",
    "        if not any(row):\n",
    "            continue\n",
    "        \n",
    "        row_text = ' '.join(str(cell) for cell in row if cell).replace('\\n', ' ')\n",
    "        \n",
    "        if \"(наименование компании)\" in row_text or \"выполненных в\" in row_text :\n",
    "            match = extract_company(row_text)\n",
    "            if match:\n",
    "                metadata['company'] = cut_company_name(match)\n",
    "            break\n",
    "    for row in sheet.iter_rows(max_row=15, values_only=True):\n",
    "        if not any(row):\n",
    "            continue\n",
    "            \n",
    "        row_text = ' '.join(str(cell) for cell in row if cell)\n",
    "        if not row_text:\n",
    "            continue\n",
    "            \n",
    "        # Проверяем типичные упоминания региона\n",
    "        if any(word in row_text.lower() for word in ['хмао', 'ханты', 'югра', 'ямал', 'янао']):\n",
    "            metadata['subject'] = normalize_region(row_text)\n",
    "            break\n",
    "    # Поиск лицензии и ВИНК\n",
    "    license_pattern = re.compile(r'Лицензия\\s*([А-Я]{2,}\\s*\\d+\\s*[А-Я]{2,})[\\s,]*([А-Яа-я\\-\\s]+)')\n",
    "    vink_pattern = re.compile(\n",
    "    r'ВИНК\\*\\s*((?:ПАО|АО|ООО|ЗАО|НКО)\\s*)?'  # Орг. форма (опционально, сохраняем)\n",
    "    r'(\"[^\"]*(?:\"[^\"]*)*\"|[^\"\\s]+)'  # Название (с кавычками или без)\n",
    "    r'(?=\\s*(?:доля|$|\\n))',  # Стоп-символы\n",
    "    flags=re.IGNORECASE\n",
    ")\n",
    "      \n",
    "    for row in sheet.iter_rows(values_only=True):\n",
    "        if not any(row):\n",
    "            continue\n",
    "        row_text = ' '.join(str(cell) for cell in row if cell)\n",
    "        \n",
    "        # Поиск лицензии\n",
    "        license_match = license_pattern.search(row_text)\n",
    "        if license_match and not metadata['license']:\n",
    "            metadata['license'] = license_match.group(1).strip()\n",
    "            metadata['area'] = license_match.group(2).strip().replace(\" Шельфовое продолжение\",'')\n",
    "        \n",
    "        # Поиск ВИНК\n",
    "        vink_match = vink_pattern.search(row_text)\n",
    "        if vink_match:\n",
    "            # Объединяем все непустые группы через пробел\n",
    "            combined = ' '.join(group for group in vink_match.groups() if group)\n",
    "            metadata['vink'] = combined\n",
    "    \n",
    "    return metadata\n",
    "\n",
    "def process_workbook(file_path):\n",
    "    wb = load_workbook(file_path,data_only=True)\n",
    "    all_data = []\n",
    "    i=1\n",
    "    for sheet_name in wb.sheetnames:\n",
    "        sheet = wb[sheet_name]\n",
    "        \n",
    "        # Извлекаем метаданные один раз для листа\n",
    "        metadata = extract_metadata(sheet)\n",
    "        \n",
    "        # Находим колонки с данными\n",
    "        fact_col = plan_col = None\n",
    "        for row in sheet.iter_rows(max_row=10):\n",
    "            for cell in row:\n",
    "                if cell.value and isinstance(cell.value, str):\n",
    "                    text = str(cell.value).lower()\n",
    "                    if \"2022\" in text and \"факт\" in text:\n",
    "                        fact_col = cell.column_letter\n",
    "                    elif \"2023\" in text and \"план\" in text:\n",
    "                        plan_col = cell.column_letter\n",
    "        \n",
    "        if not fact_col or not plan_col:\n",
    "            print(f\"Не найдены колонки с данными в листе: {sheet_name}\")\n",
    "            continue\n",
    "        \n",
    "        # Сначала собираем ВСЕ показатели за 2022 год\n",
    "        records_2022 = {\n",
    "            'ID':i,\n",
    "            'Субъект РФ': metadata.get(\"subject\"),\n",
    "            'Период (год)': 2022,\n",
    "            'план/факт':'факт',\n",
    "            'Главная компания': metadata.get('company'),\n",
    "            'Недропользователь': metadata.get('vink'),\n",
    "            '№ лицензии': metadata.get('license'),\n",
    "            'участок': metadata.get('area'),\n",
    "            'Оценка выполнения лицензионных условий': None\n",
    "        }\n",
    "        i+=1\n",
    "        \n",
    "        # Затем ВСЕ показатели за 2023 год\n",
    "        records_2023 = {\n",
    "            'ID':i,\n",
    "            'Субъект РФ': metadata.get(\"subject\"),\n",
    "            'Период (год)': 2023,\n",
    "            'план/факт': 'план',\n",
    "            'Главная компания': metadata.get('company'),\n",
    "            'Недропользователь': metadata.get('vink'),\n",
    "            '№ лицензии': metadata.get('license'),\n",
    "            'участок': metadata.get('area'),\n",
    "            'Оценка выполнения лицензионных условий': None\n",
    "        }\n",
    "        i+=1\n",
    "        # Заполняем показатели\n",
    "        for row in sheet.iter_rows(min_row=2, values_only=True):\n",
    "            if not row or not isinstance(row[0], str):\n",
    "                continue\n",
    "                \n",
    "            p_p = row[0].strip()\n",
    "            if p_p in INDICATOR_MAPPING:\n",
    "                col_name = INDICATOR_MAPPING[p_p]\n",
    "                records_2022[col_name] = row[column_index_from_string(fact_col)-1]\n",
    "                records_2023[col_name] = row[column_index_from_string(plan_col)-1]\n",
    "        \n",
    "        # Добавляем в общий список\n",
    "        all_data.append(records_2022)\n",
    "        all_data.append(records_2023)\n",
    "    \n",
    "    # Создаем DataFrame\n",
    "    df = pd.DataFrame(all_data)\n",
    "    \n",
    "    # Заполняем None для отсутствующих показателей\n",
    "    for col in INDICATOR_MAPPING.values():\n",
    "        if col not in df.columns:\n",
    "            df[col] = None\n",
    "    df.iloc[:, 8] = df.iloc[:, 72]\n",
    "\n",
    "# Удаление колонки 'BU'\n",
    "    df.drop(df.columns[72], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Сохранение в Excel и CSV\n",
    "def save_results(df, base_path):\n",
    "    # Сохранение в Excel\n",
    "    excel_path = f\"{base_path}/результат.xlsx\"\n",
    "    df.to_excel(excel_path, index=False)\n",
    "    \n",
    "    # Сохранение в CSV\n",
    "    csv_path = f\"{base_path}/результат.csv\"\n",
    "    df.to_csv(csv_path, index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "175ef2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#запуск ф-ий\n",
    "out_path =r'/home/tm/Рабочий стол/ projects/etl_project/results' \n",
    "result_df = process_workbook(path_in)\n",
    "save_results(result_df,out_path)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47b1202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Базовые права на БД назначены\n",
      "Права на схему public выданы\n",
      "Право CREATEDB выдано\n",
      "Право CREATE выдано\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "\n",
    "# Параметры подключения к PostgreSQL (админские права)\n",
    "admin_db_config = {\n",
    "    'host': '127.0.0.1',\n",
    "    'port': '5432',\n",
    "    'user': 'postgres', \n",
    "    'password': '123',  # Администратор БД\n",
    "    'database': 'postgres'  # Подключаемся к системной БД\n",
    "}\n",
    "\n",
    "# Параметры для новой БД\n",
    "new_db_name = \"oil_gas_db\"\n",
    "new_user = \"oil_analyst\"\n",
    "new_password = \"pass\"\n",
    "\n",
    "try:\n",
    "    # Подключаемся к PostgreSQL\n",
    "    conn = psycopg2.connect(**admin_db_config)\n",
    "    \n",
    "    # Устанавливаем режим autocommit на уровне соединения\n",
    "    conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "    \n",
    "    with conn.cursor() as cur:\n",
    "        # 1. Создаем базу данных\n",
    "        cur.execute(sql.SQL(\"CREATE DATABASE {}\").format(\n",
    "            sql.Identifier(new_db_name)))\n",
    "        print(f\"База данных {new_db_name} создана\")\n",
    "        \n",
    "        # 2. Создаем пользователя\n",
    "        cur.execute(sql.SQL(\"CREATE USER {} WITH PASSWORD %s\").format(\n",
    "            sql.Identifier(new_user)), [new_password])\n",
    "        print(f\"Пользователь {new_user} создан\")\n",
    "        \n",
    "        # 3. Даем права на базу данных\n",
    "        cur.execute(sql.SQL(\"GRANT ALL PRIVILEGES ON DATABASE {} TO {}\").format(\n",
    "            sql.Identifier(new_db_name),\n",
    "            sql.Identifier(new_user)))\n",
    "        print(\"Базовые права на БД назначены\")\n",
    "        \n",
    "        # 4. Даем права на схему public\n",
    "        cur.execute(sql.SQL(\"GRANT ALL PRIVILEGES ON SCHEMA public TO {}\").format(\n",
    "            sql.Identifier(new_user)))\n",
    "        print(\"Права на схему public выданы\")\n",
    "        \n",
    "        # 5. Разрешаем создание временных таблиц\n",
    "        cur.execute(sql.SQL(\"ALTER USER {} CREATEDB\").format(\n",
    "            sql.Identifier(new_user)))\n",
    "        print(\"Право CREATEDB выдано\")\n",
    "        \n",
    "        # 6. Разрешаем создание объектов в БД\n",
    "        cur.execute(sql.SQL(\"GRANT CREATE ON DATABASE {} TO {}\").format(\n",
    "            sql.Identifier(new_db_name),\n",
    "            sql.Identifier(new_user)))\n",
    "        print(\"Право CREATE выдано\")\n",
    "\n",
    "except psycopg2.Error as e:\n",
    "    print(f\"Ошибка PostgreSQL: {e}\")\n",
    "finally:\n",
    "    if 'conn' in locals():\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e180242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Все права успешно предоставлены\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "\n",
    "# Подключение как администратор\n",
    "admin_conn = psycopg2.connect(\n",
    "    host='localhost',\n",
    "    port='5432',\n",
    "    user='postgres',\n",
    "    password='123',  # ваш пароль postgres\n",
    "    database='postgres'\n",
    ")\n",
    "admin_conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "\n",
    "try:\n",
    "    with admin_conn.cursor() as admin_cur:\n",
    "        # Даем все права на базу данных\n",
    "        admin_cur.execute(sql.SQL(\"\"\"\n",
    "            GRANT ALL PRIVILEGES ON DATABASE oil_gas_db TO oil_analyst;\n",
    "            GRANT ALL PRIVILEGES ON SCHEMA public TO oil_analyst;\n",
    "            GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO oil_analyst;\n",
    "            ALTER DEFAULT PRIVILEGES IN SCHEMA public \n",
    "            GRANT ALL PRIVILEGES ON TABLES TO oil_analyst;\n",
    "        \"\"\"))\n",
    "        print(\"Все права успешно предоставлены\")\n",
    "finally:\n",
    "    admin_conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34c7b6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "DB_CONFIG = {\n",
    "    'host': 'localhost',\n",
    "    'port': '5432',\n",
    "    'dbname': 'oil_gas_db',\n",
    "    'user': \"oil_analyst\",\n",
    "    'password': \"pass\"\n",
    "}\n",
    "\n",
    "# Создаем подключение\n",
    "engine = create_engine(f\"postgresql://{DB_CONFIG['user']}:{DB_CONFIG['password']}@{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['dbname']}\")\n",
    "def generate_create_table_sql():\n",
    "    \"\"\"Генерирует SQL для создания таблицы с колонками для всех индикаторов\"\"\"\n",
    "    columns = []\n",
    "    \n",
    "    # Базовые колонки (метаданные)\n",
    "    base_columns = [\n",
    "        'id SERIAL PRIMARY KEY',\n",
    "        'subject VARCHAR(100)',\n",
    "        'company VARCHAR(200)',\n",
    "        'license_number VARCHAR(50)',\n",
    "        'area VARCHAR(200)',\n",
    "        'vink VARCHAR(200)',\n",
    "        'year INTEGER',\n",
    "        'plan_fact VARCHAR(10)',\n",
    "        'license_evaluation FLOAT'\n",
    "    ]\n",
    "    \n",
    "    # Колонки для индикаторов (тип FLOAT для числовых значений)\n",
    "    indicator_columns = [f'\"{indicator}\" FLOAT' for indicator in INDICATOR_MAPPING.values()]\n",
    "    \n",
    "    return f\"CREATE TABLE IF NOT EXISTS oil_gas_data ({', '.join(base_columns + indicator_columns)})\"\n",
    "\n",
    "def load_to_postgres(df):\n",
    "    \"\"\"Загружает данные в PostgreSQL с правильной структурой таблицы\"\"\"\n",
    "    conn = psycopg2.connect(**DB_CONFIG)\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    # Создаем таблицу\n",
    "    cur.execute(generate_create_table_sql())\n",
    "    \n",
    "    # Подготавливаем SQL для вставки\n",
    "    columns = [\n",
    "        'subject', 'company', 'license_number', 'area', 'vink', \n",
    "        'year', 'plan_fact', 'license_evaluation'\n",
    "    ] + list(INDICATOR_MAPPING.values())\n",
    "    \n",
    "    placeholders = ', '.join(['%s'] * len(columns))\n",
    "    sql = f\"INSERT INTO oil_gas_data ({', '.join(columns)}) VALUES ({placeholders})\"\n",
    "    \n",
    "    # Загружаем данные построчно\n",
    "    for _, row in df.iterrows():\n",
    "        values = []\n",
    "        for col in columns:\n",
    "            # Преобразуем None в NULL для PostgreSQL\n",
    "            value = row[col] if pd.notna(row[col]) else None\n",
    "            values.append(value)\n",
    "        \n",
    "        cur.execute(sql, values)\n",
    "    \n",
    "    conn.commit()\n",
    "    print(f\"Успешно загружено {len(df)} записей\")\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e636356",
   "metadata": {},
   "outputs": [
    {
     "ename": "InsufficientPrivilege",
     "evalue": "permission denied for schema public\nLINE 1: CREATE TABLE IF NOT EXISTS oil_gas_data (id SERIAL PRIMARY K...\n                                   ^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInsufficientPrivilege\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mload_to_postgres\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 44\u001b[39m, in \u001b[36mload_to_postgres\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m     41\u001b[39m cur = conn.cursor()\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# Создаем таблицу\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m \u001b[43mcur\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerate_create_table_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[38;5;66;03m# Подготавливаем SQL для вставки\u001b[39;00m\n\u001b[32m     47\u001b[39m columns = [\n\u001b[32m     48\u001b[39m     \u001b[33m'\u001b[39m\u001b[33msubject\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcompany\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlicense_number\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33marea\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mvink\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m     49\u001b[39m     \u001b[33m'\u001b[39m\u001b[33myear\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mplan_fact\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlicense_evaluation\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     50\u001b[39m ] + \u001b[38;5;28mlist\u001b[39m(INDICATOR_MAPPING.values())\n",
      "\u001b[31mInsufficientPrivilege\u001b[39m: permission denied for schema public\nLINE 1: CREATE TABLE IF NOT EXISTS oil_gas_data (id SERIAL PRIMARY K...\n                                   ^\n"
     ]
    }
   ],
   "source": [
    "load_to_postgres(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6f7f70",
   "metadata": {},
   "source": [
    "Алгоритм действий:<br>\n",
    "установил необходимые библиотеки и импортировал их\n",
    "указал полный путь к файлу из которого я буду получать данные \n",
    "все управление идет из основной функции process_workbook(file_path)\n",
    "в которой вызываются остальные функции , которые помогают преобразовать данные к ним попорядку\n",
    "так как в эксель файле есть формулы , я подключил книгу с атрибутом data_only=True, что позволяет в ячейках читать только значения \n",
    "for sheet_name in wb.sheetnames: - основной цикл в котором я прохожусь по всем листам эксель\n",
    "metadata = extract_metadata(sheet) - первая надпись которая нас встречает она же первая функция в ней я получаю данные в словарь , это такие даные как :\n",
    "            'Субъект РФ'   - в функции метадата пробегаю по листу и каждую строку в которой есть такие метки как  ['хмао', 'ханты', 'югра', 'ямал', 'янао'] вызываю функцию normalize_region в которой идет предобработка отчистка данных от личшних символов и идет сравнение с регуляркой которые перечислены в словаре REGION_NORMALIZATION и возвращается значение того ключа где регулярное выражение сработало, при желании как словарь , так и метки можно дополнять субъектами рф , список и словарь легко расширяется\n",
    "            'Главная компания' - слов нет , насколько сложно вытаскивать компанию из заголовка, так же как и в субъекте вызывается функция extract_company где идет тройная предобработка даннх после я пытался разными способами с нейросетью вытянуть организацию, пока не подобрал слово к которому можно привязаться и в строке от которого скорее всего будет идти то самое наименование организации - это \"(наименование компании)\" , но оказалось все не так просто , на одном листе этого слова не было , пришлось цепляться еще к одной метке которая срабатывает в том случае условие выглядит так if \"(наименование компании)\" in row_text or \"выполненных в\" in row_text : \n",
    "            'Недропользователь' - так же вытягивал но уже боле простым способом из строки ВИНК*  - как я понял из логики таблицы\n",
    "            '№ лицензии' - аналогичным способом \n",
    "            'участок' - идет рядом с лицензией , через запятую поэтому он тоже легко вытянулся\n",
    "после заполренный словарь метадата я возвращаю в главную функцию \n",
    "дальше цикл я просто накожу имя колонки с показателям иза 2022 и за 2023 год , завожу переменную инициализирую единицей и после каждой строки увеличиваю значение - это для ID \n",
    "завожу два словаря records 2022 и  records 2023  в которые буду подставлять данные из словаря метадата и также некоторые поля таблицы мне надо чередовать в рамках каждой фирмы сначала 2022 потом 2023 поэтому два словаря \n",
    "в цикле имеется вот такая конструкция            \n",
    "            ```p_p = row[0].strip() -получаю из пункта пп номер показателя которые у нас в первом столбце\n",
    "            if p_p in INDICATOR_MAPPING: - выше вы видели словарь с перечислением всех показателей и тут мы просто если он есть \n",
    "                col_name = INDICATOR_MAPPING[p_p] - то присваем переменной имя колонки  и ниже заполняем два словаря по имени колонки  из   факта  и плана в соотвествующие словари\n",
    "                records_2022[col_name] = row[column_index_from_string(fact_col)-1]\n",
    "                records_2023[col_name] = row[column_index_from_string(plan_col)-1]```\n",
    "после они построчно записываются в список all_data на основе которого потом строится датафрейм там я удалил лишний столбец который у меня повился , а еще я в метаданных когда формировал имя комании дописал функцию , чтобы лишние слова не записывались в имя организации , где строку сплитовал по пробелу и если больше трех желементов обрезал массив и возвращал потом заджоиную функцию.\n",
    "\n",
    "тз довольно не простое в целом у меня не него ушло наверное 8 часов работы непрерывной, надеюсь я покрыл все требования к тз и правильно понял логику таблиц.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d9bcbc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

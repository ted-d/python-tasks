{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89c65bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b112cb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_in =r\"C:\\Users\\Tony_Montana\\Downloads\\in.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f033805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.utils import column_index_from_string\n",
    "\n",
    "# Ваш существующий INDICATOR_MAPPING остается без изменений\n",
    "INDICATOR_MAPPING = {\n",
    "    # Добыча УВ сырья\n",
    "    \"1.1.\": \"ДОБЫЧА УВ СЫРЬЯ. Нефть, млн. т\",\n",
    "    \"1.2.\": \"ДОБЫЧА УВ СЫРЬЯ. Конденсат, млн. т\",\n",
    "    \"1.3.\": \"ДОБЫЧА УВ СЫРЬЯ. Газ (свободный + газовая шапка), млрд. м3\",\n",
    "    \"1.4.\": \"ДОБЫЧА УВ СЫРЬЯ. Попутный газ, млрд. м3\",\n",
    "    \n",
    "    # Затраты на ГРР\n",
    "    \"2.\": \"ЗАТРАТЫ НА ГРР. ВСЕГО*, млн. р.\",\n",
    "    \"2.1.\": \"Глубокое бурение. всего, млн. р.\",\n",
    "    \"2.1.1.\": \"Параметрическое, млн. р.\",\n",
    "    \"2.1.2.\": \"Поисковое, млн. р.\",\n",
    "    \"2.1.3.\": \"Разведочное, млн. р.\",\n",
    "    \"2.2.\": \"Сейсморазведка. всего, млн. р.\",\n",
    "    \"2.2.1.\": \"Сейсморазведка 2Д, млн. р.\",\n",
    "    \"2.2.2.\": \"Сейсморазведка 3Д, млн. р.\",\n",
    "    \"2.3.\": \"НИОКР, млн. р.\",\n",
    "    \"2.4.\": \"Прочие работы, млн. р.\",\n",
    "    \n",
    "    # Результаты ГРР\n",
    "    \"3.1.\": \"Глубокое бурение. всего, м\",\n",
    "    \"3.1.1.\": \"Параметрическое, м\",\n",
    "    \"3.1.2.\": \"Поисковое, м\",\n",
    "    \"3.1.3.\": \"Разведочное, м\",\n",
    "    \"3.1.4.\": \"Закончено строительством поисковых скважин, шт.\",\n",
    "    \"3.1.4.1.\": \"Из них продуктивных, шт.\",\n",
    "    \"3.1.5.\": \"Закончено строительством разведочных скважин, шт.\",\n",
    "    \"3.1.5.1.\": \"Из них продуктивных, шт.\",\n",
    "    \n",
    "    # Прирост запасов АВ1C1\n",
    "    \"3.2.1.\": \"Прирост запасов УВ категории АВ1C1. Нефть, млн. т\",\n",
    "    \"3.2.1.1.\": \"Прирост запасов УВ категории АВ1C1. Нефть за счет ГРР, млн. т\",\n",
    "    \"3.2.1.2.\": \"Прирост запасов УВ категории АВ1C1. Нефть за счет переоценки, млн. т\",\n",
    "    \"3.2.2.\": \"Прирост запасов УВ категории АВ1C1. Конденсат, млн. т\",\n",
    "    \"3.2.2.1.\": \"Прирост запасов УВ категории АВ1C1. Конденсат за счет ГРР, млн. т\",\n",
    "    \"3.2.2.2.\": \"Прирост запасов УВ категории АВ1C1. Конденсат за счет переоценки, млн. т\",\n",
    "    \"3.2.3.\": \"Прирост запасов УВ категории АВ1C1. Газ (свободный + газовая шапка), млрд. м3\",\n",
    "    \"3.2.3.1.\": \"Прирост запасов УВ категории АВ1C1. Газ за счет ГРР, млрд. м3\",\n",
    "    \"3.2.3.2.\": \"Прирост запасов УВ категории АВ1C1. Газ за счет переоценки, млрд. м3\",\n",
    "    \"3.2.4.1.\": \"Прирост запасов УВ категории АВ1C1. Нефть на вновь открытых месторождениях, млн. т\",\n",
    "    \"3.2.4.2.\": \"Прирост запасов УВ категории АВ1C1. Конденсат на вновь открытых месторождениях, млн. т\",\n",
    "    \"3.2.4.3.\": \"Прирост запасов УВ категории АВ1C1. Газ на вновь открытых месторождениях, млрд. м3\",\n",
    "    \n",
    "    # Прирост запасов В2С2\n",
    "    \"3.3.1.\": \"Прирост запасов УВ категории В2С2. Нефть, млн. т\",\n",
    "    \"3.3.1.1.\": \"Прирост запасов УВ категории В2С2. Нефть за счет ГРР, млн. т\",\n",
    "    \"3.3.1.2.\": \"Прирост запасов УВ категории В2С2. Нефть за счет переоценки, млн. т\",\n",
    "    \"3.3.2.\": \"Прирост запасов УВ категории В2С2. Конденсат, млн. т\",\n",
    "    \"3.3.2.1.\": \"Прирост запасов УВ категории В2С2. Конденсат за счет ГРР, млн. т\",\n",
    "    \"3.3.2.2.\": \"Прирост запасов УВ категории В2С2. Конденсат за счет переоценки, млн. т\",\n",
    "    \"3.3.3.\": \"Прирост запасов УВ категории В2С2. Газ (свободный + газовая шапка), млрд. м3\",\n",
    "    \"3.3.3.1.\": \"Прирост запасов УВ категории В2С2. Газ за счет ГРР, млрд. м3\",\n",
    "    \"3.3.3.2.\": \"Прирост запасов УВ категории В2С2. Газ за счет переоценки, млрд. м3\",\n",
    "    \"3.3.4.1.\": \"Прирост запасов УВ категории В2С2. Нефть на вновь открытых месторождениях, млн. т\",\n",
    "    \"3.3.4.2.\": \"Прирост запасов УВ категории В2С2. Конденсат на вновь открытых месторождениях, млн. т\",\n",
    "    \"3.3.4.3.\": \"Прирост запасов УВ категории В2С2. Газ на вновь открытых месторождениях, млрд. м3\",\n",
    "    \n",
    "    # Нетрадиционные источники УВС\n",
    "    \"3.4.1.\": \"Нетрадиционные источники УВС. Прирост категории АВ1С1. Сланцевый газ, млрд. м3\",\n",
    "    \"3.4.2.\": \"Нетрадиционные источники УВС. Прирост категории АВ1С1. Сланцевая нефть, млн. т\",\n",
    "    \"3.5.1.\": \"Нетрадиционные источники УВС. Прирост категории С2 (В2). Сланцевый газ, млрд. м3\",\n",
    "    \"3.5.2.\": \"Нетрадиционные источники УВС. Прирост категории С2 (В2). Сланцевая нефть, млн. т\",\n",
    "    \n",
    "    # Сейсморазведка\n",
    "    \"3.6.1.\": \"Сейсморазведка 2Д, пог. км\",\n",
    "    \"3.6.2.\": \"Сейсморазведка 3Д, км2\",\n",
    "    \n",
    "    # Подготовлено сейсморазведкой перспективных объектов\n",
    "    \"3.7.1.\": \"Подготовлено сейсморазведкой перспективных объектов с ресурсами. Нефть, шт.\",\n",
    "    \"3.7.1.1\": \"Подготовлено сейсморазведкой перспективных объектов с ресурсами. Нефть, млн. т\",\n",
    "    \"3.7.2.\": \"Подготовлено сейсморазведкой перспективных объектов с ресурсами. Газ (конденсат), шт.\",\n",
    "    \"3.7.2.1\": \"Подготовлено сейсморазведкой перспективных объектов с ресурсами. Газ, млрд. м3\",\n",
    "    \"3.7.2.2\": \"Подготовлено сейсморазведкой перспективных объектов с ресурсами. Конденсат, млн. т\",\n",
    "    \n",
    "    # Выведено (списано) по результатам бурения\n",
    "    \"3.8.1.\": \"Выведено (списано) по результатам бурения поисковых объектов. Нефть, шт.\",\n",
    "    \"3.8.1.1\": \"Выведено (списано) по результатам бурения поисковых объектов. Нефть, млн. т\",\n",
    "    \"3.8.2.\": \"Выведено (списано) по результатам бурения поисковых объектов. Газ (конденсат), шт.\",\n",
    "    \"3.8.2.1\": \"Выведено (списано) по результатам бурения поисковых объектов. Газ, млрд. м3\",\n",
    "    \"3.8.2.2\": \"Выведено (списано) по результатам бурения поисковых объектов. Конденсат, млн. т\",\n",
    "    \n",
    "    # Состояние ресурсов\n",
    "    \"3.9.1.\": \"Состояние ресурсов кат. Д0 на 01.01.2023 г. Нефть, млн. т\",\n",
    "    \"3.9.2.\": \"Состояние ресурсов кат. Д0 на 01.01.2023 г. Газ, млрд. м3\",\n",
    "    \"3.9.3.\": \"Состояние ресурсов кат. Д0 на 01.01.2023 г. Конденсат, млн. т\",\n",
    "    \n",
    "    # Открыто месторождений\n",
    "    \"3.10.\": \"Открыто месторождений, всего, шт.\",\n",
    "    \"3.10.1.\": \"Открыто месторождений, нефтяных, шт.\",\n",
    "    \"3.10.2.\": \"Открыто месторождений, газовых, шт.\",\n",
    "    \"3.10.3.\": \"Открыто месторождений, нефтегазовых и газонефтяных, шт.\",\n",
    "    \"3.10.4.\": \"Открыто месторождений, нефтегазоконденсатных и газоконденсатных, шт.\",\n",
    "    \n",
    "    # Оценка выполнения лицензионных условий\n",
    "    \"4.\": \"Оценка выполнения лицензионных условий, балл\"\n",
    "}\n",
    "REGION_NORMALIZATION = {\n",
    "    r'хмао[\\s\\-]?югр[аы]': 'ХМАО — Югра',\n",
    "    r'ханты[\\s\\-]мансийск[\\w\\s\\-]*югр[аы]': 'ХМАО — Югра',\n",
    "    r'ямал[\\w\\s\\-]*округ': 'Ямало-Ненецкий АО',\n",
    "    r'ямальск[\\w\\s\\-]*район': 'Ямало-Ненецкий АО',\n",
    "    r'янао': 'Ямало-Ненецкий АО'\n",
    "}\n",
    "def normalize_region(region_name):\n",
    "    \"\"\"Приводит название региона к стандартному виду\"\"\"\n",
    "    if not region_name or not isinstance(region_name, str):\n",
    "        return None\n",
    "    \n",
    "    # Приводим к нижнему регистру и удаляем лишние символы\n",
    "    cleaned = re.sub(r'[^\\w\\s\\-]', '', region_name.lower().strip())\n",
    "    \n",
    "    # Ищем совпадения с нашим словарем\n",
    "    for pattern, standard in REGION_NORMALIZATION.items():\n",
    "        if re.search(pattern, cleaned):\n",
    "            return standard\n",
    "    \n",
    "    # Если не нашли совпадение, возвращаем оригинал с базовой очисткой\n",
    "    return region_name.strip()\n",
    "def extract_company(text):\n",
    "    # Нормализация текста\n",
    "    text = re.sub(r'_{2,}', ' ', text)  # Заменяем множественные подчеркивания\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Заменяем множественные пробелы\n",
    "    text = text.replace('«', '\"').replace('»', '\"')  # Стандартизируем кавычки\n",
    "    \n",
    "    # Улучшенный паттерн поиска\n",
    "    pattern = r'''\n",
    "        (ПАО|АО|ООО|ЗАО|НКО)  # Тип организации\n",
    "        \\s*                    # Возможные пробелы\n",
    "        \"                      # Открывающая кавычка\n",
    "        (                      # Начинаем захват названия\n",
    "          (?:                  # Группа без захвата\n",
    "            [^\"\\n]+            # Любые символы кроме кавычки и переноса строки\n",
    "            (?:\"[^\"\\n]+)*      # Вложенные кавычки с текстом\n",
    "          )                    #\n",
    "        )                      # Конец названия\n",
    "        \"                      # Закрывающая кавычка\n",
    "        (?!\\S)                 # Не должно быть букв/цифр после\n",
    "    '''\n",
    "    \n",
    "    match = re.search(pattern, text, re.VERBOSE | re.IGNORECASE)\n",
    "    if match:\n",
    "        company_type = match.group(1).upper()\n",
    "        company_name = match.group(2)\n",
    "        \n",
    "        # Очистка названия (без обрезания существенной части)\n",
    "        clean_name = company_name.strip(' _-')\n",
    "        return f'{company_type} \"{clean_name}\"'\n",
    "    \n",
    "    # Дополнительный поиск для случаев с большим количеством пробелов\n",
    "    alt_pattern = r'(ПАО|АО|ООО|ЗАО|НКО)\\s+\"([^\"]+)\"'\n",
    "    alt_match = re.search(alt_pattern, text, re.IGNORECASE)\n",
    "    if alt_match:\n",
    "        return f'{alt_match.group(1).upper()} \"{alt_match.group(2).strip()}\"'\n",
    "    \n",
    "    return None\n",
    "def cut_company_name(company):\n",
    "    company = company.split()\n",
    "    if len(company)>=3:\n",
    "        company=company[:3]\n",
    "    return \" \".join(company)\n",
    "\n",
    "def extract_metadata(sheet):\n",
    "    \"\"\"Извлекает метаданные из листа\"\"\"\n",
    "    metadata = {\n",
    "        'subject':None,\n",
    "        'company': None,\n",
    "        'license': None,\n",
    "        'area': None,\n",
    "        'vink': None\n",
    "    }\n",
    "    \n",
    "    # Поиск названия компании\n",
    "    for row in sheet.iter_rows(values_only=True):\n",
    "        if not any(row):\n",
    "            continue\n",
    "        \n",
    "        row_text = ' '.join(str(cell) for cell in row if cell).replace('\\n', ' ')\n",
    "        \n",
    "        if \"(наименование компании)\" in row_text or \"выполненных в\" in row_text :\n",
    "            match = extract_company(row_text)\n",
    "            if match:\n",
    "                metadata['company'] = cut_company_name(match)\n",
    "            break\n",
    "    for row in sheet.iter_rows(max_row=15, values_only=True):\n",
    "        if not any(row):\n",
    "            continue\n",
    "            \n",
    "        row_text = ' '.join(str(cell) for cell in row if cell)\n",
    "        if not row_text:\n",
    "            continue\n",
    "            \n",
    "        # Проверяем типичные упоминания региона\n",
    "        if any(word in row_text.lower() for word in ['хмао', 'ханты', 'югра', 'ямал', 'янао']):\n",
    "            metadata['subject'] = normalize_region(row_text)\n",
    "            break\n",
    "    # Поиск лицензии и ВИНК\n",
    "    license_pattern = re.compile(r'Лицензия\\s*([А-Я]{2,}\\s*\\d+\\s*[А-Я]{2,})[\\s,]*([А-Яа-я\\-\\s]+)')\n",
    "    vink_pattern = re.compile(\n",
    "    r'ВИНК\\*\\s*((?:ПАО|АО|ООО|ЗАО|НКО)\\s*)?'  # Орг. форма (опционально, сохраняем)\n",
    "    r'(\"[^\"]*(?:\"[^\"]*)*\"|[^\"\\s]+)'  # Название (с кавычками или без)\n",
    "    r'(?=\\s*(?:доля|$|\\n))',  # Стоп-символы\n",
    "    flags=re.IGNORECASE\n",
    ")\n",
    "      \n",
    "    for row in sheet.iter_rows(values_only=True):\n",
    "        if not any(row):\n",
    "            continue\n",
    "        row_text = ' '.join(str(cell) for cell in row if cell)\n",
    "        \n",
    "        # Поиск лицензии\n",
    "        license_match = license_pattern.search(row_text)\n",
    "        if license_match and not metadata['license']:\n",
    "            metadata['license'] = license_match.group(1).strip()\n",
    "            metadata['area'] = license_match.group(2).strip().replace(\" Шельфовое продолжение\",'')\n",
    "        \n",
    "        # Поиск ВИНК\n",
    "        vink_match = vink_pattern.search(row_text)\n",
    "        if vink_match:\n",
    "            # Объединяем все непустые группы через пробел\n",
    "            combined = ' '.join(group for group in vink_match.groups() if group)\n",
    "            metadata['vink'] = combined\n",
    "    \n",
    "    return metadata\n",
    "\n",
    "def process_workbook(file_path):\n",
    "    wb = load_workbook(file_path,data_only=True)\n",
    "    all_data = []\n",
    "    i=1\n",
    "    for sheet_name in wb.sheetnames:\n",
    "        sheet = wb[sheet_name]\n",
    "        \n",
    "        # Извлекаем метаданные один раз для листа\n",
    "        metadata = extract_metadata(sheet)\n",
    "        \n",
    "        # Находим колонки с данными\n",
    "        fact_col = plan_col = None\n",
    "        for row in sheet.iter_rows(max_row=10):\n",
    "            for cell in row:\n",
    "                if cell.value and isinstance(cell.value, str):\n",
    "                    text = str(cell.value).lower()\n",
    "                    if \"2022\" in text and \"факт\" in text:\n",
    "                        fact_col = cell.column_letter\n",
    "                    elif \"2023\" in text and \"план\" in text:\n",
    "                        plan_col = cell.column_letter\n",
    "        \n",
    "        if not fact_col or not plan_col:\n",
    "            print(f\"Не найдены колонки с данными в листе: {sheet_name}\")\n",
    "            continue\n",
    "        \n",
    "        # Сначала собираем ВСЕ показатели за 2022 год\n",
    "        records_2022 = {\n",
    "            'ID':i,\n",
    "            'Субъект РФ': metadata.get(\"subject\"),\n",
    "            'Период (год)': 2022,\n",
    "            'план/факт':'факт',\n",
    "            'Главная компания': metadata.get('company'),\n",
    "            'Недропользователь': metadata.get('vink'),\n",
    "            '№ лицензии': metadata.get('license'),\n",
    "            'участок': metadata.get('area'),\n",
    "            'Оценка выполнения лицензионных условий': None\n",
    "        }\n",
    "        i+=1\n",
    "        \n",
    "        # Затем ВСЕ показатели за 2023 год\n",
    "        records_2023 = {\n",
    "            'ID':i,\n",
    "            'Субъект РФ': metadata.get(\"subject\"),\n",
    "            'Период (год)': 2023,\n",
    "            'план/факт': 'план',\n",
    "            'Главная компания': metadata.get('company'),\n",
    "            'Недропользователь': metadata.get('vink'),\n",
    "            '№ лицензии': metadata.get('license'),\n",
    "            'участок': metadata.get('area'),\n",
    "            'Оценка выполнения лицензионных условий': None\n",
    "        }\n",
    "        i+=1\n",
    "        # Заполняем показатели\n",
    "        for row in sheet.iter_rows(min_row=2, values_only=True):\n",
    "            if not row or not isinstance(row[0], str):\n",
    "                continue\n",
    "                \n",
    "            p_p = row[0].strip()\n",
    "            if p_p in INDICATOR_MAPPING:\n",
    "                col_name = INDICATOR_MAPPING[p_p]\n",
    "                records_2022[col_name] = row[column_index_from_string(fact_col)-1]\n",
    "                records_2023[col_name] = row[column_index_from_string(plan_col)-1]\n",
    "        \n",
    "        # Добавляем в общий список\n",
    "        all_data.append(records_2022)\n",
    "        all_data.append(records_2023)\n",
    "    \n",
    "    # Создаем DataFrame\n",
    "    df = pd.DataFrame(all_data)\n",
    "    \n",
    "    # Заполняем None для отсутствующих показателей\n",
    "    for col in INDICATOR_MAPPING.values():\n",
    "        if col not in df.columns:\n",
    "            df[col] = None\n",
    "    df.iloc[:, 8] = df.iloc[:, 72]\n",
    "\n",
    "# Удаление колонки 'BU'\n",
    "    df.drop(df.columns[72], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "# Использование\n",
    "\n",
    "result_df = process_workbook(path_in)\n",
    "\n",
    "# Сохранение в Excel\n",
    "result_df.to_excel(\"результат.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6f7f70",
   "metadata": {},
   "source": [
    "Алгоритм действий:<br>\n",
    "установил необходимые библиотеки и импортировал их\n",
    "указал полный путь к файлу из которого я буду получать данные \n",
    "все управление идет из основной функции process_workbook(file_path)\n",
    "в которой вызываются остальные функции , которые помогают преобразовать данные к ним попорядку\n",
    "так как в эксель файле есть формулы , я подключил книгу с атрибутом data_only=True, что позволяет в ячейках читать только значения \n",
    "for sheet_name in wb.sheetnames: - основной цикл в котором я прохожусь по всем листам эксель\n",
    "metadata = extract_metadata(sheet) - первая надпись которая нас встречает она же первая функция в ней я получаю данные в словарь , это такие даные как :\n",
    "            'Субъект РФ'   - в функции метадата пробегаю по листу и каждую строку в которой есть такие метки как  ['хмао', 'ханты', 'югра', 'ямал', 'янао'] вызываю функцию normalize_region в которой идет предобработка отчистка данных от личшних символов и идет сравнение с регуляркой которые перечислены в словаре REGION_NORMALIZATION и возвращается значение того ключа где регулярное выражение сработало, при желании как словарь , так и метки можно дополнять субъектами рф , список и словарь легко расширяется\n",
    "            'Главная компания' - слов нет , насколько сложно вытаскивать компанию из заголовка, так же как и в субъекте вызывается функция extract_company где идет тройная предобработка даннх после я пытался разными способами с нейросетью вытянуть организацию, пока не подобрал слово к которому можно привязаться и в строке от которого скорее всего будет идти то самое наименование организации - это \"(наименование компании)\" , но оказалось все не так просто , на одном листе этого слова не было , пришлось цепляться еще к одной метке которая срабатывает в том случае условие выглядит так if \"(наименование компании)\" in row_text or \"выполненных в\" in row_text : \n",
    "            'Недропользователь' - так же вытягивал но уже боле простым способом из строки ВИНК*  - как я понял из логики таблицы\n",
    "            '№ лицензии' - аналогичным способом \n",
    "            'участок' - идет рядом с лицензией , через запятую поэтому он тоже легко вытянулся\n",
    "после заполренный словарь метадата я возвращаю в главную функцию \n",
    "дальше цикл я просто накожу имя колонки с показателям иза 2022 и за 2023 год , завожу переменную инициализирую единицей и после каждой строки увеличиваю значение - это для ID \n",
    "завожу два словаря records 2022 и  records 2023  в которые буду подставлять данные из словаря метадата и также некоторые поля таблицы мне надо чередовать в рамках каждой фирмы сначала 2022 потом 2023 поэтому два словаря \n",
    "в цикле имеется вот такая конструкция            \n",
    "            ```p_p = row[0].strip() -получаю из пункта пп номер показателя которые у нас в первом столбце\n",
    "            if p_p in INDICATOR_MAPPING: - выше вы видели словарь с перечислением всех показателей и тут мы просто если он есть \n",
    "                col_name = INDICATOR_MAPPING[p_p] - то присваем переменной имя колонки  и ниже заполняем два словаря по имени колонки  из   факта  и плана в соотвествующие словари\n",
    "                records_2022[col_name] = row[column_index_from_string(fact_col)-1]\n",
    "                records_2023[col_name] = row[column_index_from_string(plan_col)-1]```\n",
    "после они построчно записываются в список all_data на основе которого потом строится датафрейм там я удалил лишний столбец который у меня повился , а еще я в метаданных когда формировал имя комании дописал функцию , чтобы лишние слова не записывались в имя организации , где строку сплитовал по пробелу и если больше трех желементов обрезал массив и возвращал потом заджоиную функцию.\n",
    "\n",
    "тз довольно не простое в целом у меня не него ушло наверное 8 часов работы непрерывной, надеюсь я покрыл все требования к тз и правильно понял логику таблиц.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d9bcbc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s_ound",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
